# app.py

import streamlit as st
import numpy as np
import librosa
import joblib
import io
from pydub import AudioSegment
import os

# Set ffmpeg path for pydub (needed on Streamlit Cloud)
AudioSegment.converter = "/usr/bin/ffmpeg"

# === Load Trained Model ===
@st.cache_resource
def load_model():
    model_path = "models/voice_gender_model.pkl"
    if not os.path.exists(model_path):
        st.error("Model file not found. Please check the path.")
        return None
    return joblib.load(model_path)

model = load_model()

# === Feature Extraction Function ===
def extract_features(uploaded_file):
    try:
        # Convert uploaded file to WAV in memory
        audio = AudioSegment.from_file(uploaded_file)
        
        # Reject files shorter than 0.5 seconds
        if len(audio) < 500:
            st.warning("âš ï¸ Audio is too short (< 0.5s). Please upload a longer file.")
            return None

        st.write(f"ðŸ“ Audio duration: {len(audio)/1000:.2f} seconds")

        wav_io = io.BytesIO()
        audio.export(wav_io, format="wav")
        wav_io.seek(0)

        # Load with librosa
        y, sr = librosa.load(wav_io, sr=22050)

        if y.size == 0:
            st.warning("âš ï¸ Audio contains no valid sound.")
            return None

        # Extract Features
        mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)
        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)
        centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr).T, axis=0)
        zcr = np.mean(librosa.feature.zero_crossing_rate(y=y).T, axis=0)

        return np.hstack([mfcc, chroma, centroid, zcr])
    
    except Exception as e:
        st.error(f"âŒ Feature extraction failed: {e}")
        return None

# === Streamlit UI ===
st.set_page_config(page_title="Voice Gender Classifier", page_icon="ðŸŽ™ï¸")
st.title("ðŸŽ™ï¸ Voice Gender Classifier")
st.markdown("Upload an audio file (WAV, MP3, M4A, OGG, etc.) and get a gender prediction using AI and signal processing.")

uploaded_file = st.file_uploader("ðŸŽ§ Upload an audio file", type=["wav", "mp3", "m4a", "flac", "aac", "ogg"])

if uploaded_file:
    st.audio(uploaded_file, format='audio/wav')

    with st.spinner("ðŸ” Extracting features and predicting..."):
        features = extract_features(uploaded_file)

        if features is not None and model is not None:
            prediction = model.predict([features])[0]
            st.success(f"ðŸ§  Predicted Gender: **{prediction.capitalize()}**")
        elif model is None:
            st.error("âŒ Model failed to load. Please check deployment.")
